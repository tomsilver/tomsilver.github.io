<h3 id="research">research areas</h3>
<p><br></p>

<p><img src="assets/img/behavior-blog-post-image12.gif" alt="image" style="float: left; width: 300px; height: 200px; margin-right:50px;"></p>

<h5 id="learning-abstractions-for-planning">Learning abstractions for hierarchical planning</h5>

<p>Abstractions allow robots to first focus on the high-level aspects of a task before getting bogged down in details. We would like a robot to automatically learn abstractions&mdash;<a href="https://arxiv.org/abs/2203.09634" target="_blank" rel="noopener noreferrer">state abstractions (predicates)</a> and <a href="https://arxiv.org/abs/2206.10680" target="_blank" rel="noopener noreferrer">action abstractions (skills)</a>&mdash;that are specialized for planning in its domain. We are especially interested in abstractions for <a href="https://arxiv.org/abs/2010.01083">task and motion planning</a>. (Image credit: <a href="https://nishanthjkumar.com/">Nishanth Kumar</a>)</p>

<p><br></p>

<p><video controls width="300" autoplay loop style="float: left; margin-top:10px; margin-right:50px;"><source src="assets/video/blocksworld-program-synthesis.mp4" type="video/mp4" /></p>
<h5 id="program-synthesis-for-planning">Program synthesis for planning</h5>

<p>We want robots to be like self-supervised software engineers, writing their own code and growing libraries that can be used to solve increasingly difficult decision-making problems. We use <a href="https://arxiv.org/abs/2305.11014">LLMs</a>, <a href="https://arxiv.org/abs/1904.06317">Bayesian program learning</a>, <a href="https://arxiv.org/abs/2005.02259">inductive logic programming</a>, <a href="https://arxiv.org/abs/2109.11082">SAT solvers</a>, and <a href="https://arxiv.org/abs/2204.10420">heuristic search</a> to synthesize programs.</p>

<p><br><br></p>

<p><video controls width="300" autoplay loop style="float: left; margin-top:5px; margin-right:50px;"><source src="assets/video/ploi-compressed.mp4" type="video/mp4" /></p>
<h5 id="learning-to-accelerate-planning">Learning to accelerate planning</h5>

<p>Even with good abstractions, online planning can be slow, especially in high-dimensional environments with many objects. Robots should learn to plan better and faster over time. We can automatically accelerate planning by learning <a href="https://arxiv.org/abs/2009.05613">object-centric task abstractions</a>, learning to <a href="https://arxiv.org/abs/2007.13202">self-impose constraints</a>, or learning <a href="https://arxiv.org/abs/2109.14830">heuristics</a>.</p>

<p><br><br></p>

<p><video controls width="300" autoplay loop style="float: left; margin-top:5px; margin-right:50px;"><source src="assets/video/spot-sweeping-compressed.mp4" type="video/mp4" /></p>
<h5 id="planning-to-learn">Planning to learn</h5>
<p>Robots should plan to practice to get better at planning. They should rapidly learn to specialize to the objects, goals, preferences, and constraints that are unique to their deployment. We can plan to learn <a href="https://arxiv.org/abs/2402.15025">samplers</a>, <a href="https://arxiv.org/abs/2303.04912">predicates</a>, and <a href="https://arxiv.org/abs/2001.08299">operators</a> for bilevel planning. Our ultimate goal is to create a virtuous cycle of learning and planning.</p>

<p><br><br></p>